{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2eFDN9xvLhX",
        "outputId": "c95243e4-4f43-4a0a-a89c-473938e685d3"
      },
      "outputs": [],
      "source": [
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ipNiJXEEwC6v"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/Master_Thesis/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from transformers import (AutoTokenizer,\n",
        "                          AutoModelForCausalLM,\n",
        "                          BitsAndBytesConfig)\n",
        "\n",
        "import torch\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qynq3-p5w7Uq"
      },
      "outputs": [],
      "source": [
        "config_data = json.load(open(\"config.json\"))\n",
        "HF_TOKEN = config_data[\"HF_TOKEN\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ4FjNbnxlQL"
      },
      "source": [
        "## Quantisation Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8rH7A6eDxhzu"
      },
      "outputs": [],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_90W4Vgybdr"
      },
      "source": [
        "## Load Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ba00a37006f0495699bbaa336ebf18ae",
            "554c79167eeb40889dd58817be54ebf3",
            "8160204d1bcb416881adc4fefffd1c19",
            "9937a3a26a484c809e2b03037076f016",
            "e09c33b307014ef894fe3bc77352bab3",
            "7eb0429941b944078f25ca7c1ff4b2ed",
            "3991cad23516497d9aaebf00750f42d3",
            "e71873115e2d43dfac5b781b2f81b5c4",
            "1b6bef8e763c47c9a608dc9fd6f586c4",
            "4842ff0601094590a6f10bdd2f701a14",
            "b8a33c51422949e2af4d450a30d4261b"
          ]
        },
        "id": "bY3bAqrH70ek",
        "outputId": "67f268ed-5ff0-44b6-c335-16ed301c09fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3-70B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id, token\u001b[38;5;241m=\u001b[39mHF_TOKEN)\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHF_TOKEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:565\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    564\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m )\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3246\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3242\u001b[0m         device_map_without_lm_head \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3243\u001b[0m             key: device_map[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m modules_to_not_convert\n\u001b[1;32m   3244\u001b[0m         }\n\u001b[1;32m   3245\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m-> 3246\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3247\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3248\u001b[0m \u001b[38;5;124;03m                Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\u001b[39;00m\n\u001b[1;32m   3249\u001b[0m \u001b[38;5;124;03m                the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\u001b[39;00m\n\u001b[1;32m   3250\u001b[0m \u001b[38;5;124;03m                these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\u001b[39;00m\n\u001b[1;32m   3251\u001b[0m \u001b[38;5;124;03m                `device_map` to `from_pretrained`. Check\u001b[39;00m\n\u001b[1;32m   3252\u001b[0m \u001b[38;5;124;03m                https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\u001b[39;00m\n\u001b[1;32m   3253\u001b[0m \u001b[38;5;124;03m                for more details.\u001b[39;00m\n\u001b[1;32m   3254\u001b[0m \u001b[38;5;124;03m                \"\"\"\u001b[39;00m\n\u001b[1;32m   3255\u001b[0m             )\n\u001b[1;32m   3256\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m device_map_without_lm_head\n\u001b[1;32m   3258\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mValueError\u001b[0m: \n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        "
          ]
        }
      ],
      "source": [
        "model_id = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, token=HF_TOKEN)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    token=HF_TOKEN,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=bnb_config\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlXC6Ie52iAT"
      },
      "source": [
        "## Data load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "DwwuwasB2hZ1",
        "outputId": "e9f1aa3e-e31b-45eb-9a84-d30abfd95855"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In fact as I said, a lot of the Azure use case...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>So we continue to build for high AFN, or Amazo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>On tech and content, that's going to be a comb...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>And what you'll see is that basically people u...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Our goal really is to kick-start an ecosystem ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9793</th>\n",
              "      <td>I actually think over the next couple of years...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9794</th>\n",
              "      <td>That said, I don't think it’s growing as fast ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9795</th>\n",
              "      <td>So I think you do see some interplay there on ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9796</th>\n",
              "      <td>There they're really two key dynamics, the fir...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9797</th>\n",
              "      <td>Even at decreasing growth rates, we are still ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9798 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "0     In fact as I said, a lot of the Azure use case...      1\n",
              "1     So we continue to build for high AFN, or Amazo...      1\n",
              "2     On tech and content, that's going to be a comb...      0\n",
              "3     And what you'll see is that basically people u...      0\n",
              "4     Our goal really is to kick-start an ecosystem ...      0\n",
              "...                                                 ...    ...\n",
              "9793  I actually think over the next couple of years...      0\n",
              "9794  That said, I don't think it’s growing as fast ...      1\n",
              "9795  So I think you do see some interplay there on ...      1\n",
              "9796  There they're really two key dynamics, the fir...      1\n",
              "9797  Even at decreasing growth rates, we are still ...      1\n",
              "\n",
              "[9798 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"data/argument_relation_class.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "maeNsH5I0-rk",
        "outputId": "7b903619-2f65-4079-fba1-a66204a69dc0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In fact as I said, a lot of the Azure use case...</td>\n",
              "      <td>Related</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>So we continue to build for high AFN, or Amazo...</td>\n",
              "      <td>Related</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>On tech and content, that's going to be a comb...</td>\n",
              "      <td>Unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>And what you'll see is that basically people u...</td>\n",
              "      <td>Unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Our goal really is to kick-start an ecosystem ...</td>\n",
              "      <td>Unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9793</th>\n",
              "      <td>I actually think over the next couple of years...</td>\n",
              "      <td>Unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9794</th>\n",
              "      <td>That said, I don't think it’s growing as fast ...</td>\n",
              "      <td>Related</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9795</th>\n",
              "      <td>So I think you do see some interplay there on ...</td>\n",
              "      <td>Related</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9796</th>\n",
              "      <td>There they're really two key dynamics, the fir...</td>\n",
              "      <td>Related</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9797</th>\n",
              "      <td>Even at decreasing growth rates, we are still ...</td>\n",
              "      <td>Related</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9798 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text      label\n",
              "0     In fact as I said, a lot of the Azure use case...    Related\n",
              "1     So we continue to build for high AFN, or Amazo...    Related\n",
              "2     On tech and content, that's going to be a comb...  Unrelated\n",
              "3     And what you'll see is that basically people u...  Unrelated\n",
              "4     Our goal really is to kick-start an ecosystem ...  Unrelated\n",
              "...                                                 ...        ...\n",
              "9793  I actually think over the next couple of years...  Unrelated\n",
              "9794  That said, I don't think it’s growing as fast ...    Related\n",
              "9795  So I think you do see some interplay there on ...    Related\n",
              "9796  There they're really two key dynamics, the fir...    Related\n",
              "9797  Even at decreasing growth rates, we are still ...    Related\n",
              "\n",
              "[9798 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# map labels 1 to Related and 0 to Unrelated\n",
        "df[\"label\"] = df[\"label\"].map({1: \"Related\", 0: \"Unrelated\"})\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "oNJQH5yQ2tLx",
        "outputId": "318fb727-bfb5-4292-8d4e-d1abe4cc71f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>claim</th>\n",
              "      <th>premise</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In fact as I said, a lot of the Azure use case...</td>\n",
              "      <td>Related</td>\n",
              "      <td>In fact as I said, a lot of the Azure use case...</td>\n",
              "      <td>I even look at the growth of virtual machine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>So we continue to build for high AFN, or Amazo...</td>\n",
              "      <td>Related</td>\n",
              "      <td>So we continue to build for high AFN, or Amazo...</td>\n",
              "      <td>Because paid unit growth continues to be stro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>On tech and content, that's going to be a comb...</td>\n",
              "      <td>Unrelated</td>\n",
              "      <td>On tech and content, that's going to be a comb...</td>\n",
              "      <td>We're continuing to build the products that a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>And what you'll see is that basically people u...</td>\n",
              "      <td>Unrelated</td>\n",
              "      <td>And what you'll see is that basically people u...</td>\n",
              "      <td>because the best of the people creating those...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Our goal really is to kick-start an ecosystem ...</td>\n",
              "      <td>Unrelated</td>\n",
              "      <td>Our goal really is to kick-start an ecosystem ...</td>\n",
              "      <td>And then rest of world, we saw some countries...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9793</th>\n",
              "      <td>I actually think over the next couple of years...</td>\n",
              "      <td>Unrelated</td>\n",
              "      <td>I actually think over the next couple of years...</td>\n",
              "      <td>We certainly have additional delivery capabil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9794</th>\n",
              "      <td>That said, I don't think it’s growing as fast ...</td>\n",
              "      <td>Related</td>\n",
              "      <td>That said, I don't think it’s growing as fast ...</td>\n",
              "      <td>I mean, you really can't tell the difference,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9795</th>\n",
              "      <td>So I think you do see some interplay there on ...</td>\n",
              "      <td>Related</td>\n",
              "      <td>So I think you do see some interplay there on ...</td>\n",
              "      <td>That means more time in video, and that does ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9796</th>\n",
              "      <td>There they're really two key dynamics, the fir...</td>\n",
              "      <td>Related</td>\n",
              "      <td>There they're really two key dynamics, the fir...</td>\n",
              "      <td>The component that actually has impacted -- t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9797</th>\n",
              "      <td>Even at decreasing growth rates, we are still ...</td>\n",
              "      <td>Related</td>\n",
              "      <td>Even at decreasing growth rates, we are still ...</td>\n",
              "      <td>And we hear from them and we continue to see ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9798 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text      label  \\\n",
              "0     In fact as I said, a lot of the Azure use case...    Related   \n",
              "1     So we continue to build for high AFN, or Amazo...    Related   \n",
              "2     On tech and content, that's going to be a comb...  Unrelated   \n",
              "3     And what you'll see is that basically people u...  Unrelated   \n",
              "4     Our goal really is to kick-start an ecosystem ...  Unrelated   \n",
              "...                                                 ...        ...   \n",
              "9793  I actually think over the next couple of years...  Unrelated   \n",
              "9794  That said, I don't think it’s growing as fast ...    Related   \n",
              "9795  So I think you do see some interplay there on ...    Related   \n",
              "9796  There they're really two key dynamics, the fir...    Related   \n",
              "9797  Even at decreasing growth rates, we are still ...    Related   \n",
              "\n",
              "                                                  claim  \\\n",
              "0     In fact as I said, a lot of the Azure use case...   \n",
              "1     So we continue to build for high AFN, or Amazo...   \n",
              "2     On tech and content, that's going to be a comb...   \n",
              "3     And what you'll see is that basically people u...   \n",
              "4     Our goal really is to kick-start an ecosystem ...   \n",
              "...                                                 ...   \n",
              "9793  I actually think over the next couple of years...   \n",
              "9794  That said, I don't think it’s growing as fast ...   \n",
              "9795  So I think you do see some interplay there on ...   \n",
              "9796  There they're really two key dynamics, the fir...   \n",
              "9797  Even at decreasing growth rates, we are still ...   \n",
              "\n",
              "                                                premise  \n",
              "0      I even look at the growth of virtual machine ...  \n",
              "1      Because paid unit growth continues to be stro...  \n",
              "2      We're continuing to build the products that a...  \n",
              "3      because the best of the people creating those...  \n",
              "4      And then rest of world, we saw some countries...  \n",
              "...                                                 ...  \n",
              "9793   We certainly have additional delivery capabil...  \n",
              "9794   I mean, you really can't tell the difference,...  \n",
              "9795   That means more time in video, and that does ...  \n",
              "9796   The component that actually has impacted -- t...  \n",
              "9797   And we hear from them and we continue to see ...  \n",
              "\n",
              "[9798 rows x 4 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate 2 cols by split text column into claim and permise, please note separator is [SEP] then remove [SEP] from premise\n",
        "df[[\"claim\", \"premise\"]] = df[\"text\"].str.split(\"\\[SEP\\]\", n=1, expand=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OvEfzPV20ZW"
      },
      "source": [
        "## Import Few Shots Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ma_ZjJC62wry",
        "outputId": "2f1ce98f-91e5-4124-cc95-46c5335039ff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>embedding_0</th>\n",
              "      <th>embedding_1</th>\n",
              "      <th>embedding_2</th>\n",
              "      <th>embedding_3</th>\n",
              "      <th>embedding_4</th>\n",
              "      <th>embedding_5</th>\n",
              "      <th>embedding_6</th>\n",
              "      <th>embedding_7</th>\n",
              "      <th>embedding_8</th>\n",
              "      <th>embedding_9</th>\n",
              "      <th>...</th>\n",
              "      <th>embedding_1535</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>original_text</th>\n",
              "      <th>claim</th>\n",
              "      <th>premise</th>\n",
              "      <th>similarity</th>\n",
              "      <th>cluster</th>\n",
              "      <th>distance</th>\n",
              "      <th>ensamble_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.001166</td>\n",
              "      <td>0.015195</td>\n",
              "      <td>0.020202</td>\n",
              "      <td>0.057993</td>\n",
              "      <td>0.029780</td>\n",
              "      <td>0.020768</td>\n",
              "      <td>-0.008722</td>\n",
              "      <td>0.083361</td>\n",
              "      <td>0.015108</td>\n",
              "      <td>0.002257</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007224</td>\n",
              "      <td>Claim: So we're currently going through the pr...</td>\n",
              "      <td>Related</td>\n",
              "      <td>So we're currently going through the process o...</td>\n",
              "      <td>So we're currently going through the process o...</td>\n",
              "      <td>I do think, as you say, this is one of the ra...</td>\n",
              "      <td>0.502003</td>\n",
              "      <td>1</td>\n",
              "      <td>1.315122</td>\n",
              "      <td>0.186880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.031427</td>\n",
              "      <td>0.027280</td>\n",
              "      <td>0.018737</td>\n",
              "      <td>0.051260</td>\n",
              "      <td>0.071991</td>\n",
              "      <td>-0.006893</td>\n",
              "      <td>-0.004549</td>\n",
              "      <td>0.054455</td>\n",
              "      <td>-0.010775</td>\n",
              "      <td>0.004245</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.010075</td>\n",
              "      <td>Claim: There's a lot of compute that goes behi...</td>\n",
              "      <td>Related</td>\n",
              "      <td>There's a lot of compute that goes behind, thi...</td>\n",
              "      <td>There's a lot of compute that goes behind, thi...</td>\n",
              "      <td>But we're also making investments to support ...</td>\n",
              "      <td>0.503110</td>\n",
              "      <td>1</td>\n",
              "      <td>1.319654</td>\n",
              "      <td>0.183455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.032694</td>\n",
              "      <td>0.009127</td>\n",
              "      <td>0.032994</td>\n",
              "      <td>0.077050</td>\n",
              "      <td>0.043729</td>\n",
              "      <td>-0.021170</td>\n",
              "      <td>-0.045609</td>\n",
              "      <td>0.034002</td>\n",
              "      <td>0.011429</td>\n",
              "      <td>-0.005422</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.012029</td>\n",
              "      <td>Claim: And I think we're seeing impressive gro...</td>\n",
              "      <td>Related</td>\n",
              "      <td>And I think we're seeing impressive growth in ...</td>\n",
              "      <td>And I think we're seeing impressive growth in ...</td>\n",
              "      <td>We have more advertisers using the ability to...</td>\n",
              "      <td>0.490220</td>\n",
              "      <td>1</td>\n",
              "      <td>1.327836</td>\n",
              "      <td>0.162384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.044543</td>\n",
              "      <td>-0.008871</td>\n",
              "      <td>-0.046620</td>\n",
              "      <td>0.072316</td>\n",
              "      <td>0.074742</td>\n",
              "      <td>0.027691</td>\n",
              "      <td>0.005908</td>\n",
              "      <td>0.040930</td>\n",
              "      <td>0.023606</td>\n",
              "      <td>-0.004914</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002469</td>\n",
              "      <td>Claim: I think what we said was that we're rea...</td>\n",
              "      <td>Related</td>\n",
              "      <td>I think what we said was that we're really ple...</td>\n",
              "      <td>I think what we said was that we're really ple...</td>\n",
              "      <td>It's worth pointing out that, as Sheryl menti...</td>\n",
              "      <td>0.483946</td>\n",
              "      <td>1</td>\n",
              "      <td>1.331516</td>\n",
              "      <td>0.152430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.027932</td>\n",
              "      <td>0.029144</td>\n",
              "      <td>-0.035976</td>\n",
              "      <td>0.045838</td>\n",
              "      <td>0.026872</td>\n",
              "      <td>-0.028263</td>\n",
              "      <td>-0.004215</td>\n",
              "      <td>0.045149</td>\n",
              "      <td>0.023511</td>\n",
              "      <td>0.014021</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.015523</td>\n",
              "      <td>Claim: I think what you will see from us is al...</td>\n",
              "      <td>Related</td>\n",
              "      <td>I think what you will see from us is always a ...</td>\n",
              "      <td>I think what you will see from us is always a ...</td>\n",
              "      <td>This is one way to do it.</td>\n",
              "      <td>0.486009</td>\n",
              "      <td>1</td>\n",
              "      <td>1.333954</td>\n",
              "      <td>0.152055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.032296</td>\n",
              "      <td>-0.004775</td>\n",
              "      <td>0.007295</td>\n",
              "      <td>0.041451</td>\n",
              "      <td>0.019517</td>\n",
              "      <td>0.007262</td>\n",
              "      <td>-0.003846</td>\n",
              "      <td>0.011530</td>\n",
              "      <td>-0.015853</td>\n",
              "      <td>-0.000908</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.013188</td>\n",
              "      <td>Claim: And so when we look at all these things...</td>\n",
              "      <td>Unrelated</td>\n",
              "      <td>And so when we look at all these things in its...</td>\n",
              "      <td>And so when we look at all these things in its...</td>\n",
              "      <td>But most importantly, I would go back to the ...</td>\n",
              "      <td>0.509285</td>\n",
              "      <td>0</td>\n",
              "      <td>1.310327</td>\n",
              "      <td>0.198959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.026413</td>\n",
              "      <td>0.037235</td>\n",
              "      <td>0.018725</td>\n",
              "      <td>0.060326</td>\n",
              "      <td>0.047039</td>\n",
              "      <td>0.016461</td>\n",
              "      <td>-0.034583</td>\n",
              "      <td>0.070880</td>\n",
              "      <td>0.032038</td>\n",
              "      <td>-0.009449</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009677</td>\n",
              "      <td>Claim: We're seeing strong adoption across a n...</td>\n",
              "      <td>Unrelated</td>\n",
              "      <td>We're seeing strong adoption across a number o...</td>\n",
              "      <td>We're seeing strong adoption across a number o...</td>\n",
              "      <td>We've got customers that are very engaged wit...</td>\n",
              "      <td>0.503465</td>\n",
              "      <td>0</td>\n",
              "      <td>1.325382</td>\n",
              "      <td>0.178083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.015836</td>\n",
              "      <td>0.003387</td>\n",
              "      <td>0.000887</td>\n",
              "      <td>0.041545</td>\n",
              "      <td>0.064141</td>\n",
              "      <td>0.028664</td>\n",
              "      <td>-0.009169</td>\n",
              "      <td>0.072977</td>\n",
              "      <td>0.013720</td>\n",
              "      <td>-0.047401</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.014651</td>\n",
              "      <td>Claim: And there’s definitely some pricing act...</td>\n",
              "      <td>Unrelated</td>\n",
              "      <td>And there’s definitely some pricing action we ...</td>\n",
              "      <td>And there’s definitely some pricing action we ...</td>\n",
              "      <td>Obviously, we're lapping what's been good per...</td>\n",
              "      <td>0.507206</td>\n",
              "      <td>0</td>\n",
              "      <td>1.339497</td>\n",
              "      <td>0.167708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.015100</td>\n",
              "      <td>0.006221</td>\n",
              "      <td>-0.023336</td>\n",
              "      <td>0.050169</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>-0.012665</td>\n",
              "      <td>-0.024376</td>\n",
              "      <td>0.064503</td>\n",
              "      <td>0.024290</td>\n",
              "      <td>-0.005776</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000873</td>\n",
              "      <td>Claim: But I’m really confident that this is s...</td>\n",
              "      <td>Unrelated</td>\n",
              "      <td>But I’m really confident that this is somethin...</td>\n",
              "      <td>But I’m really confident that this is somethin...</td>\n",
              "      <td>Are we growing customer bases?</td>\n",
              "      <td>0.498767</td>\n",
              "      <td>0</td>\n",
              "      <td>1.341831</td>\n",
              "      <td>0.156936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.059273</td>\n",
              "      <td>0.011230</td>\n",
              "      <td>0.030089</td>\n",
              "      <td>0.033061</td>\n",
              "      <td>0.040817</td>\n",
              "      <td>0.019545</td>\n",
              "      <td>0.008647</td>\n",
              "      <td>0.102297</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>-0.029495</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>Claim: We're still focused on continuing to ha...</td>\n",
              "      <td>Unrelated</td>\n",
              "      <td>We're still focused on continuing to have that...</td>\n",
              "      <td>We're still focused on continuing to have that...</td>\n",
              "      <td>because we got a lot of customers that are wa...</td>\n",
              "      <td>0.500880</td>\n",
              "      <td>0</td>\n",
              "      <td>1.344206</td>\n",
              "      <td>0.156674</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 1545 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
              "0    -0.001166     0.015195     0.020202     0.057993     0.029780   \n",
              "1     0.031427     0.027280     0.018737     0.051260     0.071991   \n",
              "2     0.032694     0.009127     0.032994     0.077050     0.043729   \n",
              "3     0.044543    -0.008871    -0.046620     0.072316     0.074742   \n",
              "4     0.027932     0.029144    -0.035976     0.045838     0.026872   \n",
              "5     0.032296    -0.004775     0.007295     0.041451     0.019517   \n",
              "6     0.026413     0.037235     0.018725     0.060326     0.047039   \n",
              "7     0.015836     0.003387     0.000887     0.041545     0.064141   \n",
              "8     0.015100     0.006221    -0.023336     0.050169     0.014724   \n",
              "9     0.059273     0.011230     0.030089     0.033061     0.040817   \n",
              "\n",
              "   embedding_5  embedding_6  embedding_7  embedding_8  embedding_9  ...  \\\n",
              "0     0.020768    -0.008722     0.083361     0.015108     0.002257  ...   \n",
              "1    -0.006893    -0.004549     0.054455    -0.010775     0.004245  ...   \n",
              "2    -0.021170    -0.045609     0.034002     0.011429    -0.005422  ...   \n",
              "3     0.027691     0.005908     0.040930     0.023606    -0.004914  ...   \n",
              "4    -0.028263    -0.004215     0.045149     0.023511     0.014021  ...   \n",
              "5     0.007262    -0.003846     0.011530    -0.015853    -0.000908  ...   \n",
              "6     0.016461    -0.034583     0.070880     0.032038    -0.009449  ...   \n",
              "7     0.028664    -0.009169     0.072977     0.013720    -0.047401  ...   \n",
              "8    -0.012665    -0.024376     0.064503     0.024290    -0.005776  ...   \n",
              "9     0.019545     0.008647     0.102297     0.039062    -0.029495  ...   \n",
              "\n",
              "   embedding_1535                                               text  \\\n",
              "0       -0.007224  Claim: So we're currently going through the pr...   \n",
              "1       -0.010075  Claim: There's a lot of compute that goes behi...   \n",
              "2       -0.012029  Claim: And I think we're seeing impressive gro...   \n",
              "3       -0.002469  Claim: I think what we said was that we're rea...   \n",
              "4       -0.015523  Claim: I think what you will see from us is al...   \n",
              "5       -0.013188  Claim: And so when we look at all these things...   \n",
              "6       -0.009677  Claim: We're seeing strong adoption across a n...   \n",
              "7       -0.014651  Claim: And there’s definitely some pricing act...   \n",
              "8       -0.000873  Claim: But I’m really confident that this is s...   \n",
              "9        0.000729  Claim: We're still focused on continuing to ha...   \n",
              "\n",
              "       label                                      original_text  \\\n",
              "0    Related  So we're currently going through the process o...   \n",
              "1    Related  There's a lot of compute that goes behind, thi...   \n",
              "2    Related  And I think we're seeing impressive growth in ...   \n",
              "3    Related  I think what we said was that we're really ple...   \n",
              "4    Related  I think what you will see from us is always a ...   \n",
              "5  Unrelated  And so when we look at all these things in its...   \n",
              "6  Unrelated  We're seeing strong adoption across a number o...   \n",
              "7  Unrelated  And there’s definitely some pricing action we ...   \n",
              "8  Unrelated  But I’m really confident that this is somethin...   \n",
              "9  Unrelated  We're still focused on continuing to have that...   \n",
              "\n",
              "                                               claim  \\\n",
              "0  So we're currently going through the process o...   \n",
              "1  There's a lot of compute that goes behind, thi...   \n",
              "2  And I think we're seeing impressive growth in ...   \n",
              "3  I think what we said was that we're really ple...   \n",
              "4  I think what you will see from us is always a ...   \n",
              "5  And so when we look at all these things in its...   \n",
              "6  We're seeing strong adoption across a number o...   \n",
              "7  And there’s definitely some pricing action we ...   \n",
              "8  But I’m really confident that this is somethin...   \n",
              "9  We're still focused on continuing to have that...   \n",
              "\n",
              "                                             premise  similarity  cluster  \\\n",
              "0   I do think, as you say, this is one of the ra...    0.502003        1   \n",
              "1   But we're also making investments to support ...    0.503110        1   \n",
              "2   We have more advertisers using the ability to...    0.490220        1   \n",
              "3   It's worth pointing out that, as Sheryl menti...    0.483946        1   \n",
              "4                          This is one way to do it.    0.486009        1   \n",
              "5   But most importantly, I would go back to the ...    0.509285        0   \n",
              "6   We've got customers that are very engaged wit...    0.503465        0   \n",
              "7   Obviously, we're lapping what's been good per...    0.507206        0   \n",
              "8                     Are we growing customer bases?    0.498767        0   \n",
              "9   because we got a lot of customers that are wa...    0.500880        0   \n",
              "\n",
              "   distance  ensamble_similarity  \n",
              "0  1.315122             0.186880  \n",
              "1  1.319654             0.183455  \n",
              "2  1.327836             0.162384  \n",
              "3  1.331516             0.152430  \n",
              "4  1.333954             0.152055  \n",
              "5  1.310327             0.198959  \n",
              "6  1.325382             0.178083  \n",
              "7  1.339497             0.167708  \n",
              "8  1.341831             0.156936  \n",
              "9  1.344206             0.156674  \n",
              "\n",
              "[10 rows x 1545 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "few_shots = pd.read_csv(\"top_5_similar_texts.csv\")\n",
        "few_shots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "PpEOBMHy4Rh8",
        "outputId": "3d9ba413-22fc-4663-f3bf-d15f827ba27c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>embedding_0</th>\n",
              "      <th>embedding_1</th>\n",
              "      <th>embedding_2</th>\n",
              "      <th>embedding_3</th>\n",
              "      <th>embedding_4</th>\n",
              "      <th>embedding_5</th>\n",
              "      <th>embedding_6</th>\n",
              "      <th>embedding_7</th>\n",
              "      <th>embedding_8</th>\n",
              "      <th>embedding_9</th>\n",
              "      <th>...</th>\n",
              "      <th>embedding_1535</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>original_text</th>\n",
              "      <th>claim</th>\n",
              "      <th>premise</th>\n",
              "      <th>similarity</th>\n",
              "      <th>cluster</th>\n",
              "      <th>distance</th>\n",
              "      <th>ensamble_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.027932</td>\n",
              "      <td>0.029144</td>\n",
              "      <td>-0.035976</td>\n",
              "      <td>0.045838</td>\n",
              "      <td>0.026872</td>\n",
              "      <td>-0.028263</td>\n",
              "      <td>-0.004215</td>\n",
              "      <td>0.045149</td>\n",
              "      <td>0.023511</td>\n",
              "      <td>0.014021</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.015523</td>\n",
              "      <td>Claim: I think what you will see from us is al...</td>\n",
              "      <td>Related</td>\n",
              "      <td>I think what you will see from us is always a ...</td>\n",
              "      <td>I think what you will see from us is always a ...</td>\n",
              "      <td>This is one way to do it.</td>\n",
              "      <td>0.486009</td>\n",
              "      <td>1</td>\n",
              "      <td>1.333954</td>\n",
              "      <td>0.152055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.059273</td>\n",
              "      <td>0.011230</td>\n",
              "      <td>0.030089</td>\n",
              "      <td>0.033061</td>\n",
              "      <td>0.040817</td>\n",
              "      <td>0.019545</td>\n",
              "      <td>0.008647</td>\n",
              "      <td>0.102297</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>-0.029495</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>Claim: We're still focused on continuing to ha...</td>\n",
              "      <td>Unrelated</td>\n",
              "      <td>We're still focused on continuing to have that...</td>\n",
              "      <td>We're still focused on continuing to have that...</td>\n",
              "      <td>because we got a lot of customers that are wa...</td>\n",
              "      <td>0.500880</td>\n",
              "      <td>0</td>\n",
              "      <td>1.344206</td>\n",
              "      <td>0.156674</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 1545 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
              "4     0.027932     0.029144    -0.035976     0.045838     0.026872   \n",
              "9     0.059273     0.011230     0.030089     0.033061     0.040817   \n",
              "\n",
              "   embedding_5  embedding_6  embedding_7  embedding_8  embedding_9  ...  \\\n",
              "4    -0.028263    -0.004215     0.045149     0.023511     0.014021  ...   \n",
              "9     0.019545     0.008647     0.102297     0.039062    -0.029495  ...   \n",
              "\n",
              "   embedding_1535                                               text  \\\n",
              "4       -0.015523  Claim: I think what you will see from us is al...   \n",
              "9        0.000729  Claim: We're still focused on continuing to ha...   \n",
              "\n",
              "       label                                      original_text  \\\n",
              "4    Related  I think what you will see from us is always a ...   \n",
              "9  Unrelated  We're still focused on continuing to have that...   \n",
              "\n",
              "                                               claim  \\\n",
              "4  I think what you will see from us is always a ...   \n",
              "9  We're still focused on continuing to have that...   \n",
              "\n",
              "                                             premise  similarity  cluster  \\\n",
              "4                          This is one way to do it.    0.486009        1   \n",
              "9   because we got a lot of customers that are wa...    0.500880        0   \n",
              "\n",
              "   distance  ensamble_similarity  \n",
              "4  1.333954             0.152055  \n",
              "9  1.344206             0.156674  \n",
              "\n",
              "[2 rows x 1545 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top_1_examples = few_shots.iloc[[4,9]]\n",
        "top_1_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mmm7edHA4C15"
      },
      "outputs": [],
      "source": [
        "def create_few_shot_prompt(examples):\n",
        "    # Start with the base prompt explaining the task\n",
        "    prompt = \"Examples \\n\\n\"\n",
        "\n",
        "    # Add each example to the prompt\n",
        "    for i, (claim, premise, label) in enumerate(examples, 1):\n",
        "        prompt += f\"{i}. Claim: {claim}\\n   Premise: {premise}\\n  Class: {label}\\n\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bbJPprd6-z2R"
      },
      "outputs": [],
      "source": [
        "def generate_messages(claim, premise, shots_prompt):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please classify the relation between them as either Related or Unrelated. Please only generate one of the two labels.\"},\n",
        "        # {\"role\": \"system\", \"content\": shots_prompt},\n",
        "        {\"role\": \"user\", \"content\": f\"Claim: {claim}\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Premise: {premise}\"}\n",
        "    ]\n",
        "    return messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8gnyX0za_PtZ"
      },
      "outputs": [],
      "source": [
        "def generate_completions(messages):\n",
        "\n",
        "  input_ids = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\"\n",
        "  ).to(model.device)\n",
        "\n",
        "  terminators = [\n",
        "      tokenizer.eos_token_id,\n",
        "      tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "  ]\n",
        "  outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=256,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.1,\n",
        "  )\n",
        "  response = outputs[0][input_ids.shape[-1]:]\n",
        "  final_response = tokenizer.decode(response, skip_special_tokens=True)\n",
        "  print(final_response)\n",
        "  return final_response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "u5C-q5-v6O02"
      },
      "outputs": [],
      "source": [
        "def get_batch_llama_3_prediction_and_save(claim, premise, shots_prompt, batch_size, filename='zero_shot_llama-3_predictions.csv'):\n",
        "    all_data = []\n",
        "    all_objects = []\n",
        "    assert len(claim) == len(premise)\n",
        "\n",
        "    for i in range(0, len(claim), batch_size):\n",
        "        batch_claim = claim[i:i + batch_size]\n",
        "        batch_premise = premise[i:i + batch_size]\n",
        "        for c, p in zip(batch_claim, batch_premise):\n",
        "            messages = generate_messages(c, p, shots_prompt)\n",
        "            completion = generate_completions(messages)\n",
        "            all_data.append(completion)\n",
        "\n",
        "\n",
        "    df = pd.DataFrame({\"predicted_relation\": all_data})\n",
        "    df.to_csv(filename, index=False)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_QX-EAfgAAva"
      },
      "outputs": [],
      "source": [
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "2k6GdIWLAm08",
        "outputId": "46dd00c5-b5d1-4f39-eb05-c5578f697809"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Examples \\n\\n1. Claim: I think what you will see from us is always a focus on driving users and driving engagement. \\n   Premise:  This is one way to do it.\\n  Class: Related\\n2. Claim: We're still focused on continuing to have that sequential improvement, and especially as some of the things Satya talked about, which is the addition of premium services, the pace of innovation especially on the premium end. \\n   Premise:  because we got a lot of customers that are wanting to get one.\\n  Class: Unrelated\\n\""
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shots_prompt = create_few_shot_prompt(top_1_examples[[\"claim\", \"premise\", \"label\"]].values.tolist())\n",
        "shots_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnzg0iyh_6L0",
        "outputId": "92be1708-a904-4beb-e2f5-94c64e1f23e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9798\n"
          ]
        }
      ],
      "source": [
        "claim = df[\"claim\"]\n",
        "premise = df[\"premise\"]\n",
        "assert len(claim) == len(premise)\n",
        "shots_prompt = shots_prompt\n",
        "print(len(claim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onsYrNfBA5jN",
        "outputId": "b6638214-a19b-40d8-dd87-3ed5def8c6d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FP4 quantization state not initialized. Please call .cuda() or .to(device) on the LinearFP4 layer first.\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch_llama_3_prediction_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclaim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpremise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshots_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama_3_predictions\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m predictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_relation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-3-results-0shot.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "Cell \u001b[0;32mIn[13], line 11\u001b[0m, in \u001b[0;36mget_batch_llama_3_prediction_and_save\u001b[0;34m(claim, premise, shots_prompt, batch_size, filename)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch_claim, batch_premise):\n\u001b[1;32m     10\u001b[0m         messages \u001b[38;5;241m=\u001b[39m generate_messages(c, p, shots_prompt)\n\u001b[0;32m---> 11\u001b[0m         completion \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_completions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m         all_data\u001b[38;5;241m.\u001b[39mappend(completion)\n\u001b[1;32m     15\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_relation\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_data})\n",
            "Cell \u001b[0;32mIn[12], line 13\u001b[0m, in \u001b[0;36mgenerate_completions\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m      3\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m      4\u001b[0m   messages,\n\u001b[1;32m      5\u001b[0m   add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m   return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m )\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m      9\u001b[0m terminators \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[1;32m     11\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|eot_id|>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m  \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m  \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mterminators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m response \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m][input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:]\n\u001b[1;32m     21\u001b[0m final_response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(response, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/transformers/generation/utils.py:1652\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1645\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1646\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1647\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1648\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1649\u001b[0m     )\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1659\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1667\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1668\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1669\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1670\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1675\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1676\u001b[0m     )\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/transformers/generation/utils.py:2734\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2731\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2733\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2734\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2735\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2737\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2738\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2739\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2742\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1038\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1035\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1038\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1050\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:925\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    921\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    922\u001b[0m         create_custom_forward(decoder_layer), hidden_states, attention_mask, position_ids\n\u001b[1;32m    923\u001b[0m     )\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 925\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    935\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:635\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask)\u001b[0m\n\u001b[1;32m    632\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 635\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    646\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:349\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask)\u001b[0m\n\u001b[1;32m    346\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(value_states, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 349\u001b[0m     query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\n\u001b[1;32m    351\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:468\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    465\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[1;32m    467\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[0;32m--> 468\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mto(inp_dtype)\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m~/Master_Thesis/.conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:566\u001b[0m, in \u001b[0;36mmatmul_4bit\u001b[0;34m(A, B, quant_state, out, bias)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatmul_4bit\u001b[39m(\n\u001b[1;32m    560\u001b[0m     A: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    561\u001b[0m     B: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    564\u001b[0m     bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    565\u001b[0m ):\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m quant_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m%\u001b[39m quant_state\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "predictions = get_batch_llama_3_prediction_and_save(claim, premise, shots_prompt, batch_size)\n",
        "df['llama_3_predictions'] = predictions['predicted_relation'].to_list()\n",
        "df.to_csv(\"llama-3-results-0shot.csv\", index=False)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqYV-9uxQmD_"
      },
      "source": [
        "## Post Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "FPQCy4uEQeOl",
        "outputId": "fe8b6b32-1acd-4fc5-80da-20e751487c30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "llama_3_predictions\n",
              "Related      8985\n",
              "Unrelated     813\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"llama_3_predictions\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# map \"Unrelated\" and \"Related\" to Unrelated and Related\n",
        "df[\"llama_3_predictions\"] = df[\"llama_3_predictions\"].map({\"Unrelated\": \"Unrelated\", \"Related\": \"Related\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       Related\n",
              "1       Related\n",
              "2       Related\n",
              "3       Related\n",
              "4       Related\n",
              "         ...   \n",
              "9793    Related\n",
              "9794    Related\n",
              "9795    Related\n",
              "9796    Related\n",
              "9797    Related\n",
              "Name: llama_3_predictions, Length: 9798, dtype: object"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"llama_3_predictions\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "llama_3_predictions\n",
              "Related      8985\n",
              "Unrelated     813\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# if Nan then check the completion_object for \"Related\" or \"Unrelated\" and then put the value in the predicted_relation\n",
        "df[\"llama_3_predictions\"] = df[\"llama_3_predictions\"].apply(lambda x: \"Related\" if \"Related\" in str(x) else \"Unrelated\")\n",
        "df[\"llama_3_predictions\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6vH9FymBYs2"
      },
      "outputs": [],
      "source": [
        "y_true = df[\"label\"]\n",
        "y_pred = df['llama_3_predictions']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dn7Jx9UQH2i"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def report_metrics(y_true, y_pred):\n",
        "    report = classification_report(y_true, y_pred)\n",
        "    confusion = confusion_matrix(y_true, y_pred, labels=[\"Related\", \"Unrelated\"])\n",
        "    return report, confusion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWFkAnm6P9oW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Related       0.53      0.97      0.69      4899\n",
            "   Unrelated       0.85      0.14      0.24      4899\n",
            "\n",
            "    accuracy                           0.56      9798\n",
            "   macro avg       0.69      0.56      0.46      9798\n",
            "weighted avg       0.69      0.56      0.46      9798\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "report, confusion = report_metrics(y_true, y_pred)\n",
        "print(report)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "# heatmap for confusion matrix and show classes and save it\n",
        "sns.heatmap(confusion, annot=True, cmap=\"Blues\", xticklabels=[\"Related\", \"Unrelated\"], yticklabels=[\"Related\", \"Unrelated\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.savefig(\"temp_0_seed_42_llama3_70B_0_shot_classification_confusion_matrix.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72glbvQaQOuv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1b6bef8e763c47c9a608dc9fd6f586c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3991cad23516497d9aaebf00750f42d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4842ff0601094590a6f10bdd2f701a14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "554c79167eeb40889dd58817be54ebf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7eb0429941b944078f25ca7c1ff4b2ed",
            "placeholder": "​",
            "style": "IPY_MODEL_3991cad23516497d9aaebf00750f42d3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7eb0429941b944078f25ca7c1ff4b2ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8160204d1bcb416881adc4fefffd1c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e71873115e2d43dfac5b781b2f81b5c4",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b6bef8e763c47c9a608dc9fd6f586c4",
            "value": 4
          }
        },
        "9937a3a26a484c809e2b03037076f016": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4842ff0601094590a6f10bdd2f701a14",
            "placeholder": "​",
            "style": "IPY_MODEL_b8a33c51422949e2af4d450a30d4261b",
            "value": " 4/4 [01:22&lt;00:00, 17.52s/it]"
          }
        },
        "b8a33c51422949e2af4d450a30d4261b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba00a37006f0495699bbaa336ebf18ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_554c79167eeb40889dd58817be54ebf3",
              "IPY_MODEL_8160204d1bcb416881adc4fefffd1c19",
              "IPY_MODEL_9937a3a26a484c809e2b03037076f016"
            ],
            "layout": "IPY_MODEL_e09c33b307014ef894fe3bc77352bab3"
          }
        },
        "e09c33b307014ef894fe3bc77352bab3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e71873115e2d43dfac5b781b2f81b5c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
